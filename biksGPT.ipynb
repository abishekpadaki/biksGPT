{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to BiksGPT. This is a simple notebook demonstrating how I build a simple Generative Pre-trained Transformer (GPT), from first principles.\n",
        "\n",
        "This was inspired by Andrej Karpathy's nanoGPT and makemore series.\n",
        "\n",
        "I shall update and tweak this model as a way to experiment with stuff on my own. Apologies in advance if you find something broken. :)"
      ],
      "metadata": {
        "id": "PNQbKnKihEQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will begin by download the tiny shakespeare dataset, which consists of all of his works in a single txt file\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inaqk3iohDoW",
        "outputId": "5e9b2d2d-4054-462e-9a61-ae68cc9803fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-02 01:45:39--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-03-02 01:45:39 (17.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZlmLhdD8f5sP"
      },
      "outputs": [],
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of the dataset (num of characters):\", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZndOTXGiGgQ",
        "outputId": "0e81870d-d2fc-4c4e-d29e-e3960943b62a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the dataset (num of characters): 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploring the vocabulary of our dataset to see the different characters present in it\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(f'Size if vocab is: {vocab_size}\\n and the characters are: {\"\".join(chars)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6XZ4EV2iPzx",
        "outputId": "fe7b17ef-05cb-4b48-92fa-e5bdfbbd5d3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size if vocab is: 65\n",
            " and the characters are: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Building our simple Tokenizer that simply converts our vocab to a unique integer\n",
        "ch_to_int = {ch:i for i,ch in enumerate(chars)}\n",
        "int_to_ch = {i:ch for i,ch in enumerate(chars)}\n",
        "\n",
        "encoder = lambda str: [ch_to_int[char] for char in str] #encodes each character in a string with it's unique int val\n",
        "decoder = lambda int: ''.join(int_to_ch[i] for i in int) #decodes the characters in their integer forms"
      ],
      "metadata": {
        "id": "izmrJEKBjBMA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing out our tokenizer\n",
        "print(encoder('penguins are the best'))\n",
        "print(decoder(encoder('penguins are the best')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcIk-QtFnLs1",
        "outputId": "e6b061c0-3811-4f6f-d4b0-6ed8678393a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[54, 43, 52, 45, 59, 47, 52, 57, 1, 39, 56, 43, 1, 58, 46, 43, 1, 40, 43, 57, 58]\n",
            "penguins are the best\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#applying our tokenizer to our dataset using pytorch\n",
        "\n",
        "import torch\n",
        "data = torch.tensor(encoder(text), dtype=torch.long) #encode and convert to torch type tensor\n",
        "print(data.shape, data.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptmr0NH0naka",
        "outputId": "e77d7268-d7b4-4b75-b81a-06d538441c63"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's look at a small part of our dataset, before and after encoding\n",
        "print('Before:')\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK3LCFKtnvyI",
        "outputId": "2263939f-701f-4311-98b3-d44b1f733218"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('After:')\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwcXHpTmoPZ_",
        "outputId": "0c22249c-8175-4b1e-c3cf-7970ef958b83"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After:\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting our dataset ready for training\n",
        "\n",
        "#first we split our dataset into train and test sets.\n",
        "# 80% will be kept for train and the rest for test\n",
        "\n",
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "test_data = data[n:]\n",
        "\n"
      ],
      "metadata": {
        "id": "hWHAYcqJoUHw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chunking or splitting up the train set into chunks/blocks of size 9\n",
        "\n",
        "# we chunk them up so that the model can learn the importance of 9 characters and their relationship with each other, such that given the first char it will be able to predict the next token (char).\n",
        "#this is the max context size/length for predictions\n",
        "chunk_size = 9\n",
        "\n",
        "#example\n",
        "print(train_data[:chunk_size+1])\n",
        "print(decoder((train_data[:chunk_size+1]).numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YxKC1zXpB_D",
        "outputId": "67b885b5-793f-463a-93c3-d99da60a6478"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])\n",
            "First Citi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's demonstrate how the above would work\n",
        "\n",
        "x = train_data[:chunk_size]\n",
        "y = train_data[1:chunk_size+1]\n",
        "\n",
        "for t in range(chunk_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ7Kx0ZouWfB",
        "outputId": "7c41db20-0461-41b3-c66f-bef1fcc5a928"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58]) the target: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's split our training data into batches for efficient parallelism\n",
        "\n",
        "torch.manual_seed(22)\n",
        "batch_size = 4 #split our training to 4 parallel batches\n",
        "chunk_size = 9\n",
        "\n",
        "def fetch_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - chunk_size, (batch_size,)) #returns batch_size number of random integers between 0 and len(data) - chunksize\n",
        "  #These random integers will be used as starting indices for selecting chunks of data.\n",
        "  #now that we have a batch of random parts of our data, we classify them into x (dependent vars) and y (target)\n",
        "  x = torch.stack([data[i:i+chunk_size] for i in ix])\n",
        "  #here x is a stack or multiple rows (batch size num of rows) to act as input data\n",
        "  y = torch.stack([data[i+1:i+chunk_size+1] for i in ix])\n",
        "  #here y is a stack or multiple rows to act as target/output data for each tensor rows in input\n",
        "\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "ooYnxrkorVh0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = fetch_batch('train')\n",
        "print('The inputs are:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "\n",
        "print('The ouputs are:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "#As you can see below the input and outputs will be of shape [batch_size, chunk_size]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-jV3Q0tyirK",
        "outputId": "3a6d8ca4-787a-4407-a499-8c6ee86b5d25"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The inputs are:\n",
            "torch.Size([4, 9])\n",
            "tensor([[43, 56,  1, 50, 43, 39, 56, 52,  1],\n",
            "        [47, 51, 11,  0, 33, 52, 50, 43, 57],\n",
            "        [57,  1, 47, 58,  1, 43,  5, 43, 52],\n",
            "        [ 1, 46, 53, 58,  1, 39,  1, 22, 39]])\n",
            "The ouputs are:\n",
            "torch.Size([4, 9])\n",
            "tensor([[56,  1, 50, 43, 39, 56, 52,  1, 57],\n",
            "        [51, 11,  0, 33, 52, 50, 43, 57, 57],\n",
            "        [ 1, 47, 58,  1, 43,  5, 43, 52,  1],\n",
            "        [46, 53, 58,  1, 39,  1, 22, 39, 41]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's demonstrate a similar prediction example like before:\n",
        "\n",
        "for b in range(batch_size):\n",
        "  for t in range(chunk_size):\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOEb49Fiywe-",
        "outputId": "ef5185a8-8b11-4ac4-a106-85ded28a155a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is [43] the target: 56\n",
            "when input is [43, 56] the target: 1\n",
            "when input is [43, 56, 1] the target: 50\n",
            "when input is [43, 56, 1, 50] the target: 43\n",
            "when input is [43, 56, 1, 50, 43] the target: 39\n",
            "when input is [43, 56, 1, 50, 43, 39] the target: 56\n",
            "when input is [43, 56, 1, 50, 43, 39, 56] the target: 52\n",
            "when input is [43, 56, 1, 50, 43, 39, 56, 52] the target: 1\n",
            "when input is [43, 56, 1, 50, 43, 39, 56, 52, 1] the target: 57\n",
            "when input is [47] the target: 51\n",
            "when input is [47, 51] the target: 11\n",
            "when input is [47, 51, 11] the target: 0\n",
            "when input is [47, 51, 11, 0] the target: 33\n",
            "when input is [47, 51, 11, 0, 33] the target: 52\n",
            "when input is [47, 51, 11, 0, 33, 52] the target: 50\n",
            "when input is [47, 51, 11, 0, 33, 52, 50] the target: 43\n",
            "when input is [47, 51, 11, 0, 33, 52, 50, 43] the target: 57\n",
            "when input is [47, 51, 11, 0, 33, 52, 50, 43, 57] the target: 57\n",
            "when input is [57] the target: 1\n",
            "when input is [57, 1] the target: 47\n",
            "when input is [57, 1, 47] the target: 58\n",
            "when input is [57, 1, 47, 58] the target: 1\n",
            "when input is [57, 1, 47, 58, 1] the target: 43\n",
            "when input is [57, 1, 47, 58, 1, 43] the target: 5\n",
            "when input is [57, 1, 47, 58, 1, 43, 5] the target: 43\n",
            "when input is [57, 1, 47, 58, 1, 43, 5, 43] the target: 52\n",
            "when input is [57, 1, 47, 58, 1, 43, 5, 43, 52] the target: 1\n",
            "when input is [1] the target: 46\n",
            "when input is [1, 46] the target: 53\n",
            "when input is [1, 46, 53] the target: 58\n",
            "when input is [1, 46, 53, 58] the target: 1\n",
            "when input is [1, 46, 53, 58, 1] the target: 39\n",
            "when input is [1, 46, 53, 58, 1, 39] the target: 1\n",
            "when input is [1, 46, 53, 58, 1, 39, 1] the target: 22\n",
            "when input is [1, 46, 53, 58, 1, 39, 1, 22] the target: 39\n",
            "when input is [1, 46, 53, 58, 1, 39, 1, 22, 39] the target: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we mainly capture x(input) for the model to train on and the target y (output) would be used to calculate the loss"
      ],
      "metadata": {
        "id": "fEzNLYKnzTcN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's get to the juict stuff and build our NN architecture"
      ],
      "metadata": {
        "id": "WkAmVEomzz8c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}